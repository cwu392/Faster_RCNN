{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# set tf backend to allow memory to grow, instead of claiming everything\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "# use this environment flag to change which GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "keras.backend.tensorflow_backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RetinaNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adjust this to point to your downloaded/trained model\n",
    "# models can be downloaded here: https://github.com/fizyr/keras-retinanet/releases\n",
    "model_path = os.path.join('/data/a2301133/RetinaNet/snapshots/', 'resnet50_csv_50.h5')\n",
    "\n",
    "# load retinanet model\n",
    "# model = models.load_model(model_path, backbone_name='resnet50')\n",
    "\n",
    "# if the model is not converted to an inference model, use the line below\n",
    "# see: https://github.com/fizyr/keras-retinanet#converting-a-training-model-to-inference-model\n",
    "model = models.load_model(model_path, backbone_name='resnet50', convert=True)\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load label to names mapping for visualization purposes\n",
    "# labels_to_names = {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
    "labels_to_names = {}\n",
    "with open(\"SF_mapping.txt\", \"rb\") as f:\n",
    "    for line in f:\n",
    "        data = line.strip().split(',')\n",
    "        labels_to_names[int(data[1])] = data[0]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# # show images inline\n",
    "# %matplotlib inline\n",
    "\n",
    "# # automatically reload modules when they have changed\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# img_name = '402_frame_5953.jpg'\n",
    "# img_path = '/project/ibm/a2301133/402/'\n",
    "# img = cv2.imread(img_path + img_name)\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = '/project/ibm/a2301133/402/'\n",
    "# video_name = '2018-03-01_14-08-31-402_cam.mp4'\n",
    "# vidcap = cv2.VideoCapture(video_path + video_name)\n",
    "# success, image = vidcap.read()\n",
    "# count = 0\n",
    "# while success:\n",
    "#     cv2.imwrite(video_path + \"%d.jpg\" % count, image)     # save frame as JPEG file      \n",
    "#     success, image = vidcap.read()\n",
    "#     print('Read a new frame: ', success)\n",
    "#     count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run detection on example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '/project/ibm/a2301133/402/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(image_folder)\n",
    "images = [x for x in images if '.jpg' in x]\n",
    "images = sorted(images, key = lambda x: int(x[:-4]))\n",
    "threshold = 0.5\n",
    "n = len(images)\n",
    "i = 0\n",
    "with open(\"402_result_new.txt\", \"wb\") as f:\n",
    "    for img_path in images:\n",
    "        image = read_image_bgr(image_folder + img_path)\n",
    "        image = preprocess_image(image)\n",
    "        boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "        n = len(scores)\n",
    "        m = len(scores[0])\n",
    "        for i in xrange(n):\n",
    "            for j in xrange(m):\n",
    "                if scores[i][j] >= threshold:\n",
    "                    xmin, ymin, xmax, ymax = boxes[i][j][0], boxes[i][j][1], boxes[i][j][2], boxes[i][j][3]\n",
    "                    bbox = str(xmin) + ',' + str(ymin) + ',' + str(xmax) + ',' + str(ymax)\n",
    "                    f.write(str(img_path) +',' + str(bbox) + ',' + str(labels[i][j]) + ',' + str(scores[i][j]) + '\\n')\n",
    "        i += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "frames_list = []\n",
    "txt_file = open(\"402_result_new.txt\" , 'rb')\n",
    "output_path = \"402_result_new.json\"\n",
    "for line in txt_file:\n",
    "    line = line.strip().split(',')\n",
    "    frame_num = line[0]\n",
    "    f_dict = {'frame_number': str(frame_num), 'RoIs': ''}\n",
    "    xmin, ymin, xmax, ymax = int(float(line[1])), int(float(line[2])), int(float(line[3])), int(float(line[4]))\n",
    "    delta_x, delta_y = xmax - xmin, ymax - ymin\n",
    "    xmin, ymin, delta_x, delta_y = str(xmin), str(ymin), str(delta_x), str(delta_y)\n",
    "    rois_list = [xmin, ymin, delta_x, delta_y, labels_to_names.get(int(line[5]))]\n",
    "    if len(rois_list) > 0:\n",
    "        f_dict['RoIs'] = ','.join(rois_list) + ';'\n",
    "    frames_list.append(f_dict)\n",
    "\n",
    "json_dict = {'output': {'frames': frames_list}}\n",
    "with open(output_path, 'wb') as out_file:\n",
    "    json.dump(json_dict, out_file, indent = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = os.listdir(image_folder)\n",
    "data = [x for x in data if '.jpg' in x]\n",
    "data.sort()\n",
    "# data = pd.read_csv(\"198_result_new.txt\", header = None)\n",
    "# data = ['0009660.jpg']\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    image = read_image_bgr(image_folder + data[i])\n",
    "    # copy to draw on\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "\n",
    "    # process image\n",
    "    start = time.time()\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis = 0))\n",
    "    print(\"processing time: \", time.time() - start)\n",
    "\n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "\n",
    "    # visualize detections\n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        # scores are sorted so we can break\n",
    "        if score < 0.5:\n",
    "            break\n",
    "\n",
    "        color = label_color(label)\n",
    "\n",
    "        b = box.astype(int)\n",
    "        draw_box(draw, b, color=color)\n",
    "\n",
    "        caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "        draw_caption(draw, b, caption)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.axis('off')\n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)\n",
    "    plt.imshow(draw)\n",
    "    plt.savefig(image_folder + 'FasterRCNN/' + data[i], transparent=True, dpi=300, pad_inches = 0, bbox_inches = 'tight')\n",
    "#     plt.show()\n",
    "    print data[i]\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "image_folder = image_folder + 'FasterRCNN/'\n",
    "video_name = '402.avi'\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
    "images = sorted(images, key = lambda x: int(x[:-4]))\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "frame = cv2.resize(frame, (width,height))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "video = cv2.VideoWriter(image_folder + video_name, fourcc, 10, (width,height))\n",
    "\n",
    "for image in images:\n",
    "    current_image = cv2.imread(os.path.join(image_folder, image))\n",
    "    video.write(current_image)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
